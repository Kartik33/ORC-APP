{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESEARCH PAPER (https://arxiv.org/abs/1504.06375)\n",
    "# https://github.com/lc82111/Keras_HED\n",
    "# Tensorflow work here, https://github.com/harsimrat-eyeem/holy-edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all imports\n",
    "from skimage.filters import threshold_local\n",
    "import numpy as np\n",
    "import h5py\n",
    "import argparse\n",
    "import cv2,imutils\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import time as t\n",
    "# https://blog.dominodatalab.com/interactive-dashboards-in-jupyter/\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import widgets\n",
    "from pylab import rcParams\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "from statistics import mode\n",
    "import os,pytesseract,editdistance,re\n",
    "rcParams['figure.figsize'] = 7, 7\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# %load ../../src/img_utils.py\n",
    "# %load img_utils.py\n",
    "\n",
    "def showimg(img):\n",
    "    plt.imshow(img,cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "def resizeAndPad(img, size, padColor=0):\n",
    "    '''\n",
    "        Aspect Ratio Rescaling of image.\n",
    "        Throws error if height / width is not generatable.\n",
    "        Adds black padding to heigh / width appropriately.\n",
    "    '''\n",
    "    h, w = img.shape[:2]\n",
    "    sh, sw = size\n",
    "    # interpolation method\n",
    "    if h > sh or w > sw: # shrinking image\n",
    "        interp = cv2.INTER_AREA\n",
    "    else: # stretching image\n",
    "        interp = cv2.INTER_CUBIC\n",
    "\n",
    "    # aspect ratio of image\n",
    "    aspect = w/h\n",
    "\n",
    "    # compute scaling and pad sizing\n",
    "    if aspect > 1: # horizontal image\n",
    "        new_w = sw\n",
    "        new_h = np.round(new_w/aspect).astype(int)\n",
    "        pad_vert = (sh-new_h)/2\n",
    "        pad_top, pad_bot = np.floor(pad_vert).astype(int), np.ceil(pad_vert).astype(int)\n",
    "        pad_left, pad_right = 0, 0\n",
    "    elif aspect < 1: # vertical image\n",
    "        new_h = sh\n",
    "        new_w = np.round(new_h*aspect).astype(int)\n",
    "        pad_horz = (sw-new_w)/2\n",
    "        pad_left, pad_right = np.floor(pad_horz).astype(int), np.ceil(pad_horz).astype(int)\n",
    "        pad_top, pad_bot = 0, 0\n",
    "    else: # square image\n",
    "        new_h, new_w = sh, sw\n",
    "        pad_left, pad_right, pad_top, pad_bot = 0, 0, 0, 0\n",
    "\n",
    "    # set pad color\n",
    "    if len(img.shape) is 3 and not isinstance(padColor, (list, tuple, np.ndarray)): # color image but only one color provided\n",
    "        padColor = [padColor]*3\n",
    "\n",
    "    # scale and pad\n",
    "    scaled_img = cv2.resize(img, (new_w, new_h), interpolation=interp)\n",
    "    scaled_img = cv2.copyMakeBorder(scaled_img, pad_top, pad_bot, pad_left, pad_right, borderType=cv2.BORDER_CONSTANT, value=padColor)\n",
    "\n",
    "    return scaled_img\n",
    "\n",
    "def adjust_gamma(image, gamma=1.0):\n",
    "\t# build a lookup table mapping the pixel values [0, 255] to\n",
    "\t# their adjusted gamma values\n",
    "\tinvGamma = 1.0 / gamma\n",
    "\ttable = np.array([((i / 255.0) ** invGamma) * 255\n",
    "\t\tfor i in np.arange(0, 256)]).astype(\"uint8\")\n",
    " \n",
    "\t# apply gamma correction using the lookup table\n",
    "\treturn cv2.LUT(image, table)\n",
    "\n",
    "def auto_canny(image, sigma=0.33):\n",
    "\t# compute the median of the single channel pixel intensities\n",
    "\tv = np.median(image)\n",
    " \n",
    "\t# apply automatic Canny edge detection using the computed median\n",
    "\tlower = int(max(0, (1.0 - sigma) * v))\n",
    "\tupper = int(min(255, (1.0 + sigma) * v))\n",
    "\tedged = cv2.Canny(image, lower, upper)\n",
    " \n",
    "\t# return the edged image\n",
    "\treturn edged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_min_max_value(img,h=512,w=512,ch=3):\n",
    "    max_val=-1;min_val=255\n",
    "    if ch==3:\n",
    "        for i  in range(h):\n",
    "            for j in range(w):\n",
    "                if img[i][j][0] > max_val:\n",
    "                    max_val=img[i][j][0]\n",
    "                if img[i][j][1] > max_val:\n",
    "                    max_val = img[i][j][1]\n",
    "                if img[i][j][2] > max_val:\n",
    "                    max_val = img[i][j][2]\n",
    "                if img[i][j][0] < min_val:\n",
    "                    min_val=img[i][j][0]\n",
    "                if img[i][j][1] < min_val:\n",
    "                    min_val = img[i][j][1]\n",
    "                if img[i][j][2] < min_val:\n",
    "                    min_val = img[i][j][2]\n",
    "    elif ch==1:\n",
    "        for i  in range(h):\n",
    "            for j in range(w):\n",
    "                if img[i][j][0] > max_val:\n",
    "                    max_val=img[i][j][0]\n",
    "                if img[i][j][0] < min_val:\n",
    "                    min_val=img[i][j][0]\n",
    "    return min_val,max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "from keras import callbacks\n",
    "import numpy as np\n",
    "# import pdb\n",
    "# from src.utils.HED_data_parser import DataParser\n",
    "from src.networks.hed import hed\n",
    "from src.utils.HED_data_parser2 import DataParser2\n",
    "from src.utils.HED_test_parser import TestParser\n",
    "from src.networks.hed2 import hed2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_minibatches(dataParser, train=True):\n",
    "    #pdb.set_trace()\n",
    "    while True:\n",
    "        if train:\n",
    "            batch_ids = np.random.choice(dataParser.training_ids, dataParser.batch_size_train)\n",
    "        else:\n",
    "            batch_ids = np.random.choice(dataParser.validation_ids, dataParser.batch_size_train*2)\n",
    "        ims, ems, _ = dataParser.get_batch(batch_ids)\n",
    "        yield(ims, [ems, ems, ems, ems, ems, ems])\n",
    "        \n",
    "def generate_testbatches(dataParser):\n",
    "    while True:\n",
    "        batch_ids = np.random.choice(dataParser.all_ids,20)\n",
    "        ims, ems, _ = dataParser.get_batch(batch_ids)\n",
    "        yield(ims, [ems, ems, ems, ems, ems, ems])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on HED-BSDS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# model_name = 'HEDSeg3'\n",
    "# model_dir     = os.path.join('checkpoints', model_name)\n",
    "# csv_fn        = os.path.join(model_dir, 'train_log.csv')\n",
    "# checkpoint_fn = os.path.join(model_dir, 'checkpoint.{epoch:02d}-{val_loss:.2f}.hdf5')\n",
    "\n",
    "# batch_size_train = 10\n",
    "\n",
    "# # environment\n",
    "# K.set_image_data_format('channels_last')\n",
    "# K.image_data_format()\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]= '0'\n",
    "# if not os.path.isdir(model_dir): os.makedirs(model_dir)\n",
    "\n",
    "# # prepare data\n",
    "# input_shape=(512,512,3)\n",
    "# dataParser = DataParser2(batch_size_train,\n",
    "#                          train_data_dir='/home/ydalal/rasidrev/src_other_dl_projects/Keras_HED-master/',\n",
    "#                          img_mask_pair_file='train_pair.lst',\n",
    "#                          input_shape=input_shape,\n",
    "#                          train_split=0.8,\n",
    "#                          isAbsolutePath=True\n",
    "#                         )\n",
    "\n",
    "# # model\n",
    "# model = hed2(input_shape=input_shape,weights=None)\n",
    "# plot_model(model, to_file=os.path.join(model_dir, 'model.pdf'), show_shapes=True)\n",
    "\n",
    "# model.load_weights('./checkpoints/BillSeg2/checkpoint.70-0.18.hdf5')\n",
    "\n",
    "# # Training\n",
    "# # call backs\n",
    "# checkpointer = callbacks.ModelCheckpoint(filepath=checkpoint_fn, \n",
    "#                                          verbose=2, \n",
    "#                                          save_best_only=True) \n",
    "# # Make it True if space issue\n",
    "\n",
    "# csv_logger  = callbacks.CSVLogger(csv_fn, append=True, separator=';')\n",
    "\n",
    "# tensorboard = callbacks.TensorBoard(log_dir=model_dir, \n",
    "#                                     histogram_freq=0, \n",
    "#                                     batch_size=10,\n",
    "#                                     write_graph=False,\n",
    "#                                     write_grads=True,\n",
    "#                                     write_images=False)\n",
    "# # Set it to false if space issue\n",
    "\n",
    "# epochs=1024\n",
    "# train_history = model.fit_generator(\n",
    "#                     generate_minibatches(dataParser,train=True),\n",
    "#                     # max_q_size=40, workers=1,\n",
    "#                     steps_per_epoch=dataParser.steps_per_epoch,  #batch size\n",
    "#                     epochs=epochs,\n",
    "#                     validation_data=generate_minibatches(dataParser, train=True),\n",
    "#                     validation_steps=dataParser.validation_steps,\n",
    "#                     callbacks=[checkpointer, csv_logger, tensorboard])\n",
    "\n",
    "# test_generator=generate_minibatches(dataParser,train=False)\n",
    "# ims,_=next(test_generator)\n",
    "# predictions=model.predict(ims,batch_size=1,verbose=1,steps=None)\n",
    "\n",
    "# for i in range(min(2,len(ims))):\n",
    "#     img=ims[i]\n",
    "#     min_val,max_val=get_min_max_value(img)\n",
    "#     img=(img-min_val)/255\n",
    "#     plt.imshow(img);plt.show()\n",
    "#     showimg(predictions[5][i].squeeze())\n",
    "# #     for prediction in predictions:\n",
    "# #         showimg(prediction[i].squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on Bill Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model'\n",
    "model_dir     = os.path.join('/media/kartik/New Volume/model/numberplate/', model_name)\n",
    "csv_fn        = os.path.join(model_dir, 'train_log.csv')\n",
    "checkpoint_fn = os.path.join(model_dir, 'checkpoint.{epoch:02d}-{val_loss:.2f}.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 , os\n",
    "import imutils\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputPath = '/home/kartik/rasidrev/resources/new/img'\n",
    "#test_file = open()\n",
    "i = 0\n",
    "for root, dirs, files in os.walk(inputPath, topdown=False):\n",
    "    img_path = root\n",
    "    root.split('/')[-1] = 'mask'\n",
    "    mask_path = root\n",
    "    print(root.split('/')[-1] )\n",
    "    for root, dirs, files in os.walk(root, topdown=False):\n",
    "        for f in files:\n",
    "            if i == 1 :\n",
    "                print(root+f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "n = 'bhavuk'\n",
    "combined_labels_file=open('/home/kartik/rasidrev/resources/free_flow/label.txt','w')\n",
    "counter = 0\n",
    "\n",
    "for fpath in glob('/home/kartik/Downloads/totaltext/Images/Train/new/*.jpg')+glob('/home/kartik/Downloads/totaltext/Images/Train/new/*.png'):\n",
    "    imgpath=os.path.abspath(fpath)\n",
    "    maskpath='/'.join(imgpath.split('/')[:-3])+'/train_mask/new/'+imgpath.split('/')[-1]\n",
    "    #print(maskpath)\n",
    "    combined_labels_file.write(imgpath+' '+maskpath+'\\n')\n",
    "    counter = counter +1 \n",
    "combined_labels_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_list = []\n",
    "for txt in glob('/home/kartik/rasidrev/resources/label_txt/*.txt'):\n",
    "    txt_list.append(txt)\n",
    "txt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Write labels info files into a main file for training\n",
    "counter = 0\n",
    "combined_labels_file=open('/home/kartik/rasidrev/resources/all_bills_labels.txt','w')\n",
    "for fname in txt_list:\n",
    "    reader=open(fname,'r')\n",
    "    for line in reader:\n",
    "        counter = counter + 1\n",
    "        combined_labels_file.write(line)\n",
    "    reader.close()\n",
    "combined_labels_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assertion1 :  297 3\n",
      "assertion2 :  70 70\n"
     ]
    }
   ],
   "source": [
    "batch_size_train = 3\n",
    "\n",
    "# environment\n",
    "K.set_image_data_format('channels_last')\n",
    "K.image_data_format()\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= '0'\n",
    "if not os.path.isdir(model_dir): os.makedirs(model_dir)\n",
    "\n",
    "# prepare data\n",
    "input_shape=(1024,1024,3)\n",
    "dataParser = DataParser2(batch_size_train,\n",
    "#                         train_data_dir='/home/ydalal/rasidrev/resources/train_data_printed_bills/',\n",
    "                         train_data_dir='/home/kartik/rasidrev/resources/free_flow/',\n",
    "                         img_mask_pair_file='label.txt',\n",
    "                         input_shape=input_shape,\n",
    "                         train_split=0.81,\n",
    "                         isAbsolutePath=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, \n",
    "# Current model trains on 480 480 3 input picture\n",
    "model = hed2(input_shape=(1024,1024,3),weights=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if weights are not loaded during initialization, try loading them now\n",
    "# model.load_weights('./checkpoints/HEDSeg2/checkpoint.02-0.13.hdf5')\n",
    "# model.load_weights('./checkpoints/BillSeg/checkpoint.10-0.04.hdf5')\n",
    "model.load_weights('/media/kartik/New Volume/model/freeflow/model/mag/model/model/model/model/checkpoint.743-0.06.hdf5')\n",
    "# model.load_weights('./checkpoints/BillSeg_2/checkpoint.70-0.18.hdf5')\n",
    "# model.load_weights('./checkpoints/BillPredictor/checkpoint.43-0.18.hdf5')\n",
    "# model.load_weights('./checkpoints/BillSeg_4/checkpoint.27-0.13.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('/media/kartik/New Volume/model/numberplate/model/checkpoint.03-0.12.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "# call backs\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=checkpoint_fn, \n",
    "                                         verbose=2, \n",
    "                                         save_best_only=True) \n",
    "# Make it True if space issue\n",
    "\n",
    "csv_logger  = callbacks.CSVLogger(csv_fn, append=True, separator=';')\n",
    "\n",
    "tensorboard = callbacks.TensorBoard(log_dir=model_dir, \n",
    "                                    histogram_freq=0, \n",
    "                                    batch_size=2,\n",
    "                                    write_graph=False,\n",
    "                                    write_grads=True,\n",
    "                                    write_images=True)\n",
    "# Set it to false if space issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://keras.io/preprocessing/image/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # we create two instances with the same arguments\n",
    "# data_gen_args = dict(featurewise_center=True,\n",
    "#                      featurewise_std_normalization=True,\n",
    "#                      rotation_range=90.,\n",
    "#                      width_shift_range=0.1,\n",
    "#                      height_shift_range=0.1,\n",
    "#                      zoom_range=0.2)\n",
    "# image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "# mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "# # Provide the same seed and keyword arguments to the fit and flow methods\n",
    "# seed = 1\n",
    "# # image_datagen.fit(images, augment=True, seed=seed)\n",
    "# # mask_datagen.fit(masks, augment=True, seed=seed)\n",
    "# image_generator = image_datagen.flow_from_directory(\n",
    "#     '../../resources/train_mask/img',\n",
    "#     target_size=(512,512),\n",
    "#     class_mode=None,\n",
    "#     seed=seed)\n",
    "\n",
    "# mask_generator = mask_datagen.flow_from_directory(\n",
    "#     '../../resources/train_mask/mask',\n",
    "#     target_size=(512,512),\n",
    "#     class_mode=None,\n",
    "#     seed=seed)\n",
    "\n",
    "# # combine generators into one which yields image and masks\n",
    "# train_generator = zip(image_generator, mask_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# epochs=1024\n",
    "# train_history = model.fit_generator(\n",
    "#                     train_generator,\n",
    "#                     # max_q_size=40, workers=1,\n",
    "#                     steps_per_epoch=dataParser.steps_per_epoch,  #batch size\n",
    "#                 callbacks=[checkpointer, csv_logger, tensorboard])         epochs=epochs)\n",
    "    \n",
    "# #     validation_data=generate_minibatches(dataParser, train=True),\n",
    "# #                     validation_steps=dataParser.validation_steps,\n",
    "# #                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1024\n",
      "98/99 [============================>.] - ETA: 1s - loss: 0.2162 - o1_loss: 0.0807 - o2_loss: 0.0594 - o3_loss: 0.0324 - o4_loss: 0.0160 - o5_loss: 0.0161 - ofuse_loss: 0.0117 - ofuse_ofuse_pixel_error: 0.0334Epoch 00001: val_loss improved from inf to 0.19043, saving model to /media/kartik/New Volume/model/numberplate/model/checkpoint.01-0.19.hdf5\n",
      "99/99 [==============================] - 132s 1s/step - loss: 0.2155 - o1_loss: 0.0806 - o2_loss: 0.0592 - o3_loss: 0.0322 - o4_loss: 0.0159 - o5_loss: 0.0159 - ofuse_loss: 0.0116 - ofuse_ofuse_pixel_error: 0.0332 - val_loss: 0.1904 - val_o1_loss: 0.0788 - val_o2_loss: 0.0490 - val_o3_loss: 0.0262 - val_o4_loss: 0.0104 - val_o5_loss: 0.0172 - val_ofuse_loss: 0.0088 - val_ofuse_ofuse_pixel_error: 0.0285\n",
      "Epoch 2/1024\n",
      "98/99 [============================>.] - ETA: 1s - loss: 0.2134 - o1_loss: 0.0888 - o2_loss: 0.0646 - o3_loss: 0.0310 - o4_loss: 0.0112 - o5_loss: 0.0106 - ofuse_loss: 0.0072 - ofuse_ofuse_pixel_error: 0.0252Epoch 00002: val_loss did not improve\n",
      "99/99 [==============================] - 128s 1s/step - loss: 0.2126 - o1_loss: 0.0884 - o2_loss: 0.0643 - o3_loss: 0.0309 - o4_loss: 0.0112 - o5_loss: 0.0106 - ofuse_loss: 0.0072 - ofuse_ofuse_pixel_error: 0.0251 - val_loss: 0.2103 - val_o1_loss: 0.0991 - val_o2_loss: 0.0736 - val_o3_loss: 0.0246 - val_o4_loss: 0.0052 - val_o5_loss: 0.0041 - val_ofuse_loss: 0.0038 - val_ofuse_ofuse_pixel_error: 0.0157\n",
      "Epoch 3/1024\n",
      "98/99 [============================>.] - ETA: 1s - loss: 0.1954 - o1_loss: 0.0821 - o2_loss: 0.0617 - o3_loss: 0.0290 - o4_loss: 0.0089 - o5_loss: 0.0080 - ofuse_loss: 0.0056 - ofuse_ofuse_pixel_error: 0.0220Epoch 00003: val_loss improved from 0.19043 to 0.06956, saving model to /media/kartik/New Volume/model/numberplate/model/checkpoint.03-0.07.hdf5\n",
      "99/99 [==============================] - 129s 1s/step - loss: 0.1952 - o1_loss: 0.0821 - o2_loss: 0.0616 - o3_loss: 0.0290 - o4_loss: 0.0089 - o5_loss: 0.0080 - ofuse_loss: 0.0056 - ofuse_ofuse_pixel_error: 0.0219 - val_loss: 0.0696 - val_o1_loss: 0.0351 - val_o2_loss: 0.0211 - val_o3_loss: 0.0090 - val_o4_loss: 0.0021 - val_o5_loss: 8.3903e-04 - val_ofuse_loss: 0.0013 - val_ofuse_ofuse_pixel_error: 0.0071\n",
      "Epoch 4/1024\n",
      "86/99 [=========================>....] - ETA: 16s - loss: 0.1911 - o1_loss: 0.0833 - o2_loss: 0.0595 - o3_loss: 0.0266 - o4_loss: 0.0080 - o5_loss: 0.0087 - ofuse_loss: 0.0050 - ofuse_ofuse_pixel_error: 0.0208"
     ]
    }
   ],
   "source": [
    "epochs=1024\n",
    "train_history = model.fit_generator(\n",
    "                    generate_minibatches(dataParser,train=True),\n",
    "                    # max_q_size=40, workers=1,\n",
    "                    steps_per_epoch=dataParser.steps_per_epoch,  #batch size\n",
    "                    epochs=epochs,\n",
    "                    validation_data=generate_minibatches(dataParser, train=True),\n",
    "                    validation_steps=dataParser.validation_steps,\n",
    "                    callbacks=[checkpointer, csv_logger, tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs=1024\n",
    "train_history = model.fit_generator(\n",
    "    \n",
    "                    generate_minibatches(dataParser,train=True),\n",
    "                    # max_q_size=40, workers=1,\n",
    "                    steps_per_epoch=dataParser.steps_per_epoch,  #batch size\n",
    "                    epochs=epochs,\n",
    "                    validation_data=generate_minibatches(dataParser, train=True),\n",
    "                    validation_steps=dataParser.validation_steps,\n",
    "                    callbacks=[checkpointer, csv_logger, tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs=1024\n",
    "train_history = model.fit_generator(\n",
    "                    generate_minibatches(dataParser,train=True),\n",
    "                    # max_q_size=40, workers=1,\n",
    "                    steps_per_epoch=dataParser.steps_per_epoch,  #batch size\n",
    "                    epochs=epochs,\n",
    "                    validation_data=generate_minibatches(dataParser, train=True),\n",
    "                    validation_steps=dataParser.validation_steps,\n",
    "                    callbacks=[checkpointer, csv_logger, tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# First Model\n",
    "epochs=1024\n",
    "train_history = model.fit_generator(\n",
    "                    generate_minibatches(dataParser,train=True),\n",
    "                    # max_q_size=40, workers=1,\n",
    "                    steps_per_epoch=dataParser.steps_per_epoch,  #batch size\n",
    "                    epochs=epochs,\n",
    "                    validation_data=generate_minibatches(dataParser, train=True),\n",
    "                    validation_steps=dataParser.validation_steps,\n",
    "                    callbacks=[checkpointer, csv_logger, tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_generator=generate_minibatches(dataParser,train=False)\n",
    "ims,_=next(test_generator)\n",
    "predictions=model.predict(ims,batch_size=1,verbose=1,steps=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Data Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file=open('./testfile.txt','w')\n",
    "from glob import glob\n",
    "import os\n",
    "for fpath in glob('l/img/*.png'):\n",
    "    print(fpath)\n",
    "    test_file.write(os.path.abspath(fpath)+' \\n')\n",
    "test_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(1024,1024,3)\n",
    "testParser=TestParser(img_mask_pair_file='./testfile.txt',\n",
    "                      input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n5 testfile.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator=generate_testbatches(testParser)\n",
    "ims,_=next(test_generator)\n",
    "predictions=model.predict(ims,batch_size=1,verbose=1,steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for img in ims:\n",
    "    print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(min(20,len(ims))):\n",
    "    img=ims[i]\n",
    "    min_val,max_val=get_min_max_value(img)\n",
    "    img=(img-min_val)/255\n",
    "    cv2.imwrite(str(i)+'img.png',(img*255))\n",
    "    plt.imshow(img);plt.show()\n",
    "    showimg(predictions[5][i].squeeze())\n",
    "    cv2.imwrite(str(i)+'prediction.png',(predictions[5][i].squeeze()*255))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Unseen Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "input_shape=(512,512,3)\n",
    "dataParser = DataParser2(batch_size_train,\n",
    "#                         train_data_dir='/home/ydalal/rasidrev/resources/train_data_printed_bills/',\n",
    "                         train_data_dir='/',\n",
    "                         img_mask_pair_file='/home/ydalal/rasidrev/resources/all_bills_labels.txt',\n",
    "                         input_shape=input_shape,\n",
    "                         train_split=0.8,\n",
    "                         isAbsolutePath=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Miscelleneous Load Bill Data Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "\n",
    "data_dir='../../resources/train_data_photos/img/'\n",
    "mask_dir='../../resources/train_data_photos/mask/'\n",
    "\n",
    "df=pd.DataFrame(columns=['class_id','img','mask'],index=None)\n",
    "\n",
    "fileList=glob(data_dir+'*.jpg')+glob(data_dir+'*.jpeg')+glob(data_dir+'*.tif')+glob(data_dir+'*.png')\n",
    "\n",
    "counter=0\n",
    "for fpath in fileList:\n",
    "    fname=fpath.split(\"/\")[-1]\n",
    "    \n",
    "    df=df.append(\n",
    "        pd.DataFrame(\n",
    "            [['0',data_dir+fname,mask_dir+fname]],\n",
    "            columns=['class_id','img','mask'],\n",
    "            index=None)\n",
    "        )\n",
    "    counter+=1\n",
    "df=df.reset_index()\n",
    "# df=df.drop(['index'],axis=1)\n",
    "\n",
    "print('files read ... ',counter)\n",
    "\n",
    "print(df[0:1]['class_id'][0],\n",
    "      df[0:1]['img'][0],\n",
    "      df[0:1]['mask'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "999px",
    "left": "0px",
    "right": "1643px",
    "top": "111px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
